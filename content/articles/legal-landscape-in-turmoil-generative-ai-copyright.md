In Stanley Kubrick’s 2001: A Space Odyssey, HAL’s synthetic voice dro1nes to the Interviewer, “Let me put it this way, Mr. Amor. The 9000 series is the most reliable computer ever made. No 9000 computer has ever made a mistake or distorted information. We are all, by any practical definition of the words, foolproof and incapable of error.”  The AI’s words feel particularly relevant today, in a day and age where everyone has come into contact with generative AI. Far beyond IBM’s Deep Blue models playing against Gary Kasparov, modern systems have capabilities that are more expansive and disruptive.

Today’s generative AI tools are also the center of some of the most pressing legal disputes of our time. The core question revolves around whether AI can create complex artistic or expressive outputs without violating the rights of the creators whose work it used in its dataset.

Mustafa Suleyman, the head of Microsoft AI and author of The Coming Wave, warns that AI presents one of the greatest dilemmas of this century. AI has become near ubiquitous. Small teams with limited resources can build models that analyze and reproduce vast amounts of human creativity. It is increasingly being used in the work place, and conversations about it taking over for certain jobs run rampant. AI stands to transform society by upsetting the economic status quo. For Suleyman, the problem is not only innovation, but containment. How can societies enjoy the benefits of AI while preventing serious harm?

Copyright lawsuits may seem far removed from these broad societal concerns, but they are our first attempt at containment. The challenge is that courts and legislatures are working with a legal system that was never meant to address generative AI. Technology is advancing faster than lawmakers can respond. Each new case tests whether the law can adapt in real time to a system that has already been trained on much of the internet.

The lawsuits now moving through U.S. courts show how unsettled the legal landscape has become. Each case highlights a different point of tension, from the legality of acquiring and training on data, to the nature of the outputs, to the balance between protecting intellectual property and supporting innovation. Taken together, they demonstrate how difficult it is for the law to grapple with a true sea change.

In Kadrey v. Meta, a group of authors claimed that Meta used their works without permission to train its large language models (LLMs). In June 2025, Judge Vince Chhabria granted summary judgment for Meta, but his ruling was not an endorsement of Meta’s practices. He stressed that the plaintiffs had failed to build the right argument for their case: “Given the state of the record, the Court has no choice but to grant summary judgment … this ruling does not stand for the proposition that Meta’s use of copyrighted materials to train its language models is lawful. It stands only for the proposition that these plaintiffs made the wrong arguments and failed to develop a record in support of the right one.” Chhabria believed that the case might have had a different result if the plaintiffs had presented stronger evidence.

Judge Chhabria also highlighted the unprecedented nature of LLMs. On one hand, he considered the training process “highly transformative,” because Meta’s purpose was to teach the model statistical relationships between words, not to allow people access to the written works used in the training. On the other hand, he warned that LLMs could flood the market with competing content, creating indirect substitution on a massive scale. As he put it, these models can generate millions of copies or imitations of the original works in a fraction of the time it took to create the original. That, he suggested, could mean that “market dilution will often cause plaintiffs to decisively win the fourth factor — and thus win the fair use question overall.” However, since the plaintiffs could not prove actual market harm, Chhabria begrudgingly ruled in Meta’s favor. He rejected Meta’s argument that denying fair use would interfere with innovation, noting that billions of dollars were at play in this matter, and if training requires copyrighted works, the companies would “figure out a way to compensate copyright holders for it.”

The case of Bartz v. Anthropic, which was decided by Judge William Alsup, reached a similar result. Alsup described Anthropic’s use of copyrighted books to train its models as “quintessentially transformative,” stating: “Like any reader aspiring to be a writer, Anthropic’s models trained upon works not to race ahead and replicate or supplant them, but to turn a hard corner and create something different.” However, in contrast to Judge Chhabria, Alsup broke down the steps of the training process. He found that digitizing legally acquired books for training could be transformative, especially if the print copies were destroyed. This meant that there were no new unauthorized copies being created, and in practice was no different than someone digitizing their own legally acquired media. By contrast, he ruled that Anthropic’s library of pirated copies was not protected by fair use, because illegally acquiring and retaining unauthorized books created direct market harm. 

The Kadrey and Bartz case rulings highlighted the infringing nature of acquiring data to train LLMs, and did not substantially prove the infringing nature of AI outputs. The Disney and NBCUniversal v. Midjourney case may prove different. The studios allege that Midjourney’s image generation tool can generate portrayals of characters like Spider-Man with a high degree of accuracy. Unlike Kadrey and Bartz, which revolved around whether training itself was transformative, this case focuses on AI’s output. Because characters like Spider-Man are intellectual property, the potential market effect is clear: These companies are losing possible avenues to monetize their characters. For now, the jury is out on this matter, but it is only a matter of time before another potentially landmark ruling is passed down. 

Others debates are emerging across a variety of industries. Getty Images has pursued Stability AI in the United Kingdom, focusing on billions of photographs scraped from its archives without a license. Outputs featured the Getty watermark in some instances. Getty’s specific claim is based on infringement of sui generis database rights, a EU and UK protection, which protects databases in which significant investment has occurred in their creation. Stability claims that their AI training took place outside of the UK and therefore are not subject to UK Law. Getty will soon be bringing a case against Stability AI in the US as well, where sui generis rights are not present. 

These cases and others like them are coming from a variety of fields, but they all circle the same question: what is fair use when discussing a machine that can instantly transform limitless amounts of data and create outputs that compete so closely with the original? For now, these outputs may differ enough to satisfy the judges as transformative, especially with textual output. However, these LLMs have texts memorized, and if you ask it to demonstrate or teach you how to write like a particular author with examples, it will provide short snippets for educational purposes. This shows that the data is there, but as of yet, the AI guard rails prevent it from creating large and identical outputs. 

Jurisdictions around the world are currently grappling with these issues. The use of AI in the creative process is creating significant debate revolving around copyright and infringement. The European Union is introducing its AI Act, which will require that authors are given a choice to opt out of their works being used for training, and provide transparency in the data used by these LLMs. Efforts like this will need to be enacted globally, and it is the kind of containment for the new technology that Suleyman proposes in The Coming Wave. With a technology as transformative as this on a global scale, broad legislative measures and regulatory actions are necessary. If the US relies on case precedent alone to manage the AI revolution, we may find our legal system lagging behind, and legitimate authors and other creatives will be off all the worse for it. Like HAL in Space Odyssey, our AI is impressive and capable but has the capability of rendering enormous harm and in this case to our markets and livelihoods. 

 